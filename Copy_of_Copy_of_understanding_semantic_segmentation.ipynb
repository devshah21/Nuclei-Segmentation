{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10QF8B44acW_g7M6XWQq5LzNIEFFTFXLq",
      "authorship_tag": "ABX9TyPHucgP2orUA2c1H7oIfZg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devshah21/nuclei_segmentation/blob/main/Copy_of_Copy_of_understanding_semantic_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "8rMlJKT7INox"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmn7sUQhBhVv",
        "outputId": "c09b765d-d4ac-4404-c38a-5cfdbca0f703"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('gdrive/MyDrive/google_colab_files/stage1_train.zip', 'r') as zipObj:\n",
        "  zipObj.extractall('gdrive/MyDrive/google_colab_files/traindata')"
      ],
      "metadata": {
        "id": "Sbs4widxIV1m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('gdrive/MyDrive/google_colab_files/stage1_test.zip', 'r') as zipObj:\n",
        "  zipObj.extractall('gdrive/MyDrive/google_colab_files/testdata')"
      ],
      "metadata": {
        "id": "jFI6NMnPJa37"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindatapath = '/content/drive/MyDrive/google_colab_files/traindata'\n",
        "testdatapath = '/content/gdrive/MyDrive/google_colab_files/testdata'"
      ],
      "metadata": {
        "id": "O3W2p1YLgKUK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "ZwNRJt3MgoH7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainids = next(os.walk(traindatapath))[1]"
      ],
      "metadata": {
        "id": "bK_Ad-QJgxD0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    testids = next(os.walk(testdatapath))[1]\n",
        "except StopIteration:\n",
        "    testids = []"
      ],
      "metadata": {
        "id": "wKWTW7dPkrlx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgwidth = 128\n",
        "imgheight = 128\n",
        "channels = 3"
      ],
      "metadata": {
        "id": "8tWUz4ZqERqr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "xtrain = np.zeros((len(trainids), imgheight, imgwidth, channels), dtype=np.uint8)\n",
        "ytrain = np.zeros((len(trainids), imgheight, imgwidth, 1), dtype=np.bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cXRlKv5lHeT",
        "outputId": "4518ee2a-daec-41a3-ef79-a1c265e4dc7a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-119cd78b6827>:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  ytrain = np.zeros((len(trainids), imgheight, imgwidth, 1), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "nnTdkozfqbCw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the UNET Architecture now\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "63EwQNOYtKfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input((imgwidth, imgheight, channels))"
      ],
      "metadata": {
        "id": "3QP_IZWAEjEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the integer values for the model into float values by dividing by 255. \n",
        "values = tf.keras.layers.Lambda(lambda x: x/255)(inputs)\n",
        "\n",
        "# Define the first conv layer, input the parameters from the U-Net diagram\n",
        "conv1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(values)\n",
        "# Prevent overfitting by using dropout function\n",
        "conv1 = tf.keras.layers.Dropout(0.1)(conv1)\n",
        "conv1 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
        "down1 = tf.keras.layers.MaxPooling2D((2,2))(conv1)"
      ],
      "metadata": {
        "id": "EgdlBZG0EwWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the following paramaters for the rest of the UNET model. The main focus here is to just define the structure/architecture for UNET."
      ],
      "metadata": {
        "id": "vHR3iqgCOVwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(down1)\n",
        "conv2 = tf.keras.layers.Dropout(0.1)(conv2)\n",
        "conv2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
        "down2 = tf.keras.layers.MaxPooling2D((2,2))(conv2)"
      ],
      "metadata": {
        "id": "DotcTc1oM-Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(down2)\n",
        "conv3 = tf.keras.layers.Dropout(0.2)(conv3)\n",
        "conv3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
        "down3 = tf.keras.layers.MaxPooling2D((2,2))(conv3)"
      ],
      "metadata": {
        "id": "jAD9G7SOO-l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(down3)\n",
        "conv4 = tf.keras.layers.Dropout(0.2)(conv4)\n",
        "conv4 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
        "down4 = tf.keras.layers.MaxPooling2D(pool_size =(2,2))(conv4)"
      ],
      "metadata": {
        "id": "Ox6ctAEoPzdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(down4)\n",
        "conv5 = tf.keras.layers.Dropout(0.3)(conv5)\n",
        "conv5 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)"
      ],
      "metadata": {
        "id": "7tjS5dkzQoBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've finished the first half of the UNET architecture, the next step is to expand the model out after contracting it."
      ],
      "metadata": {
        "id": "MQ2o6ltJQ7sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "up6 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides = (2,2), padding = 'same')(conv5)\n",
        "up6 = tf.keras.layers.concatenate([up6, conv4]) #skip connections\n",
        "conv6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(up6)\n",
        "conv6 = tf.keras.layers.Dropout(0.2)(conv6)\n",
        "conv6 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)"
      ],
      "metadata": {
        "id": "aKdkDXuMRbrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "up7 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides = (2,2), padding = 'same')(conv6)\n",
        "up7 = tf.keras.layers.concatenate([up7, conv3]) #skip connections\n",
        "conv7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(up7)\n",
        "conv7 = tf.keras.layers.Dropout(0.2)(conv7)\n",
        "conv7 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)"
      ],
      "metadata": {
        "id": "w97ukHLWVtu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "up8 = tf.keras.layers.Conv2DTranspose(32, (2,2), strides = (2,2), padding = 'same')(conv7)\n",
        "up8 = tf.keras.layers.concatenate([up8, conv2])\n",
        "conv8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(up8)\n",
        "conv8 = tf.keras.layers.Dropout(0.1)(conv8)\n",
        "conv8 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv8) "
      ],
      "metadata": {
        "id": "9kZ4cTNA7Ofh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "up9 = tf.keras.layers.Conv2DTranspose(16, (2,2), strides = (2,2), padding = 'same')(conv8)\n",
        "up9 = tf.keras.layers.concatenate([up9, conv1], axis=3)\n",
        "conv9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(up9)\n",
        "conv9 = tf.keras.layers.Dropout(0.1)(conv9)\n",
        "conv9 = tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv9) "
      ],
      "metadata": {
        "id": "vICDFjSE-bCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = tf.keras.layers.Conv2D(1, (1,1), activation = 'sigmoid')(conv9)"
      ],
      "metadata": {
        "id": "4MCVJ6Ni-n6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[inputs], outputs = [outputs])\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "Bh7nNx5C_IgJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}